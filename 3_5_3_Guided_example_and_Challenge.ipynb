{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.5.3 Guided example and Challenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Glasiermedic/Boosting-examples/blob/master/3_5_3_Guided_example_and_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "4fyHpfzVv8pY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import ensemble\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnLZngbtv8pc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gradient boost guided example\n",
        "\n",
        "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
      ]
    },
    {
      "metadata": {
        "id": "kUr4mHvdv8pc",
        "colab_type": "code",
        "outputId": "3af5bb25-12d0-45c2-d007-71855c0c8cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv((\n",
        "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
        "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
        "\n",
        "# Definine outcome and predictors.\n",
        "# Set our outcome to 0 and 1.\n",
        "y = df['partner'] - 1\n",
        "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
        "print (X.head(10))\n",
        "#X = X.drop(['tvtot', 'pplfair', 'ppltrst', 'sclact', 'pplhlp', 'year'], axis = 1)\n",
        "\n",
        "# Make the categorical variable 'country' into dummies.\n",
        "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
        "X['people']= (df['ppltrst'] + df['pplfair'] + df['pplhlp'])/3\n",
        "X['school']= (df['sclmeet'] + df['sclact'])/2\n",
        "X = X.drop(['tvtot', 'pplfair', 'ppltrst', 'sclact', 'sclmeet', 'pplhlp', 'year'], axis = 1)\n",
        "X.agea = (X.agea)/10 \n",
        "# Create training and test sets.\n",
        "offset = int(X.shape[0] * 0.9)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
        "\n",
        "\n",
        "print (X.head(10))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  agea\n",
            "0      6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0  60.0\n",
            "1      6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0  59.0\n",
            "2      6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   1.0  24.0\n",
            "3      6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   2.0  64.0\n",
            "4      6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   2.0  55.0\n",
            "6      6    3.0      0.0      5.0     2.0    0.0      2.0     2.0   1.0  76.0\n",
            "7      6    2.0      4.0      5.0     3.0   10.0      5.0     2.0   2.0  30.0\n",
            "8      6    2.0      8.0      8.0     8.0    9.0      6.0     4.0   2.0  84.0\n",
            "9      6    4.0      4.0      4.0     8.0    7.0      4.0     2.0   2.0  62.0\n",
            "10     6    1.0      6.0      7.0     7.0    9.0      5.0     2.0   2.0  33.0\n",
            "    happy  gndr  agea  CH  CZ  DE  ES  NO  SE    people  school\n",
            "0     8.0   2.0   6.0   1   0   0   0   0   0  6.000000     4.5\n",
            "1     9.0   2.0   5.9   1   0   0   0   0   0  5.666667     2.5\n",
            "2     7.0   1.0   2.4   1   0   0   0   0   0  8.000000     4.5\n",
            "3    10.0   2.0   6.4   1   0   0   0   0   0  6.333333     4.0\n",
            "4     8.0   2.0   5.5   1   0   0   0   0   0  6.000000     4.5\n",
            "6     0.0   1.0   7.6   1   0   0   0   0   0  2.333333     2.0\n",
            "7    10.0   2.0   3.0   1   0   0   0   0   0  4.000000     3.5\n",
            "8     9.0   2.0   8.4   1   0   0   0   0   0  8.000000     5.0\n",
            "9     7.0   2.0   6.2   1   0   0   0   0   0  5.333333     3.0\n",
            "10    9.0   2.0   3.3   1   0   0   0   0   0  6.666667     3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vXn0Ymhtv8pf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here. "
      ]
    },
    {
      "metadata": {
        "id": "t0exrG_Kv8pg",
        "colab_type": "code",
        "outputId": "0eca83b8-45ad-40d9-e23c-96d6f2d9f010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
        "params = {'n_estimators': 1000,\n",
        "          'max_depth': 2,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "clf = ensemble.GradientBoostingClassifier(**params)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "predict_train = clf.predict(X_train)\n",
        "predict_test = clf.predict(X_test)\n",
        "\n",
        "# Accuracy tables.\n",
        "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
        "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
        "\n",
        "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
        "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
        "\n",
        "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
        "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
        "\n",
        "print((\n",
        "    'Training set accuracy:\\n'\n",
        "    'Percent Type I errors: {}\\n'\n",
        "    'Percent Type II errors: {}\\n\\n'\n",
        "    'Test set accuracy:\\n'\n",
        "    'Percent Type I errors: {}\\n'\n",
        "    'Percent Type II errors: {}'\n",
        ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy:\n",
            "Percent Type I errors: 0.04582651391162029\n",
            "Percent Type II errors: 0.17757774140752863\n",
            "\n",
            "Test set accuracy:\n",
            "Percent Type I errors: 0.05766871165644172\n",
            "Percent Type II errors: 0.17791411042944785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eydo4VGvv8pj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Original accuracy:\n",
        "#### Goal is to get the smallest type I and II errors\n",
        "\n",
        "#### Percent Type I errors: 0.04650845608292417\n",
        "\n",
        "#### Percent Type II errors: 0.17607746863066012\n",
        "\n",
        "#### Test set accuracy:\n",
        "#### Percent Type I errors: 0.06257668711656442\n",
        "\n",
        "#### Percent Type II errors: 0.18527607361963191\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ycZD68CIBgi1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Improved Model\n",
        "\n",
        "#### To fine tune the model we increased the number of estimators used, created a 'school' feature by combining the two school features into an average of both.  We also created a 'people' feature by combining the three people features into an average of them all.  \n",
        "\n",
        "#### Training set accuracy:\n",
        "#### Percent Type I errors: 0.04582651391162029\n",
        "#### Percent Type II errors: 0.17757774140752863\n",
        "\n",
        "#### Test set accuracy:\n",
        "#### Percent Type I errors: 0.05766871165644172\n",
        "#### Percent Type II errors: 0.17791411042944785\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xkMTR1NJv8pk",
        "colab_type": "code",
        "outputId": "1484c803-a79c-4eaf-93d5-11006c6f5227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "cell_type": "code",
      "source": [
        "feature_importance = clf.feature_importances_\n",
        "\n",
        "# Make importances relative to max importance.\n",
        "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, X.columns[sorted_idx])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.title('Variable Importance')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMwAAAEVCAYAAACsZAqhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG61JREFUeJzt3Xe4XFW5x/FvCC2E0EMXkeKPpl6Q\ncmkSpMmVgEgJUiMoIl2CoEi5BCkiAbmAInIBAyLSizSBGCDgpSkiAj9qBIL0GkBiknP/WOuEnZPT\n9jkze2bC+3mePMzs2eWd4byz1t6z3rUHtLW1EULonTkaHUAIrSQSJoQSImFCKCESJoQSImFCKCES\nJoQSImEySRMk7d/J8n0lTSi5r+0lXdCL9dokLdvJ8pGSbi95zNLb1IqkrSQt14hjVy0S5mMXAbt3\nsnyP/Fqv2b7G9t41iKlVfA/4RCTMnI0OoIlcDpwpaQXbzwJIWh5YE/hqfv4tYBTpc/snsIftf0ga\nCWwLLAg8BDwG7G57c0lLAL8GlgfmAc6yfXrhuN+QtGfe9hTbPy8GJWkh4CxgvXzcE2xf2N0bkTQM\nOBm4L8f1JnAAcAqwKvBL28fluHcG3gA2AD4Etrf9lKRFgHOBLwDTgF/b/knefxtwFDAyf26bAatK\nOgK4AbgQ+A9gbuAq24fn7cYD1wNfBz4D3AXsartN0leAMcBcwJPAnrbflLQh8DNgYeD1vP6z3b3/\neooWJrP9LnANM7cyuwHX2n5X0uLA2cAWtlcGngaOKay7JbCf7SM67Ppo4Dnbq5D+sE6W9KnC65+2\n/bm8/RhJQztsPwaYDqxCSprjJa3Ri7e0FnAtsGLe/mxS4m8OHCVp3rzeFsA5tlfM65+al58EvGVb\nwEbA/pI2Kux/gG3ZPgaYBOxm+3fAd4EhOd61gJEdthuej/lZ4MvABpIGA78BRtj+LOmzPUHSEFIC\nHmV7JeBMUoI2TCTMzC5i5oTZPS/D9qvAArZfzK/dDaxQWPdJ2091ss+DgYPyPp4FXiZ9u7Ybm197\nAngC+GKH7YcDZ9qebvs14GrSN3RP3rY93nYb8HfgTtsf5McDgfbEfMz2/+XHV5FaGkjJ9fMc25v5\nuFsW9v/7zg5qewywne0222/l4xU/pyttf2j7fVJLshywIfCC7UfzOkeQunkbAy/avi3v+7fASo08\nX4ou2czGAfNKWo/UDRmclyFpIDBa0rakP7ghpP/h7d7sYp/rkFqV5fI+l2LmL6rXCo/fIXU9ihYC\nLpc0NT8fBFzRi/fyXuHxNGAyQO7+TM/voWPcbxWOPzQ/L762dOF5p+9X0srA6ZJWycf9FKmL1u6d\nDnENBBYD3m5faHtK3tdCwIqSnihs81GO7fnOjl9vkTAFtqdLGgt8g/Q/c6zt6fnlEaTzgS/Zfl3S\nt0ldtp5cApwBnJv/WCd1eH0R4Ln8eGHSH+JShddfAr5W+PattcU6xNKeCK8Ai/LxH+aieVlPziGd\nx33N9jRJ9/Rim9eLcUiaL8fyEvC47bV7sY9KRJdsVheREmM7Zr46tjgwMSfLoqST5fl7sb/FgYdy\nsuxFarWK2+0KkL+RVwIe6LD9dcB+eZ05JZ0haa2yb6obkrRmfrwjqasJqcu1b15hMVI38MYu9vFv\nUksI6f3+JSfLFsDK9Pw5TQCWlLROfn4McCzposVSucVH0gqSLpY0oMwbrKVImA5sP036Zns5P273\nW2BRSU/nx0cDn5I0poddHgNcI+kR0h/OL4FfSVoxvz5R0sPArcDB+Xyh4/YLSjIfn3880vd3OIt7\nge9Jeo70RXFkXn40sHDuDt1FuoJ3fxf7uBK4TNJhwI9JFy8eBTYBjiddqNiwqwDyudUOwCWSngQ+\nTzrR/5CUxGdJepx0UeaKfF7WEAOiHuaTK19W3t325o2OpVVECxNCCZEwIZQQXbIQSogWJoQSWu53\nmKlTp7W99dYHjQ5jhoUXno9migeaL6ZWimfo0CHdXrJuuRZmzjkH9rxShZotHmi+mGaneFouYUJo\npEiYEEqIhAmhhEiYEEqIhAmhhEiYEEqIhAmhhEiYEEpouV/6h4+6rtEhhBZ3w5jt+rxttDAhlBAJ\nE0IJkTAhlBAJE0IJkTAhlNCvq2SSFgAuJU0dNB9phkeRZi58gTTf1DjgYuA80gyIcwHH2h4naXPg\nBGAKaaK4ndsncQuhGfW3hVkSON/2psAP87+TSfP37kSa6hPS3Fv/zOt9jTS5NKSJ63a1vQnwLrBV\nP+MJoa76+zvMK8Axkg4nzUw/GHjX9isAku7I620AbFyYlHqQpLlJ06SeL2lOUuszrp/xhNArQ4cO\n6dN2/U2YQ4FJtveQtDap6zWt8Hr7DBtTgBPzZNIz5JsOfdX245LO7mcsIfTaa6+91+nynhKpv12y\nxYBn8uPtSechi0paWNIgYFh+7T7S1KtIWlzSSXn5gsDzedLpTUn3EwmhafU3YcYCh0n6AykpliRN\nFXo36WLAg6QW53JgsqR7Sff7aJ+/9xzgHtIFgVOBH0paihCaVM3nJZO0IzAu3z3qVuB42/fWav/D\nR10XE6mFfrlhzHbddcm6nTWmHoMv5wPGSXofeLiWyRJCo9U8YWyPJd9VK4TZTStOFdvWVXPaCEOH\nDumyeW+UZoupleKZ7SbyC6GRImFCKCESJoQSokS5Bxf84MuVHi80t2hhQighEiaEEiJhQiihVMJI\nGibpynoFE0KzixYmhBL6cpVsfkmXAF8ArgDupUOZMalg7EjgI+DTwJW2T5Q0HngAWBsYBIwgjVI+\nz/YdkuYBHgNke2p/3lgI9dCXhFkNWIXUOj0HPE4qM35O0lhSmfF7pKT4DDAVeELSuXn7N2xvKukg\nUgHaxaTEuQPYDLi5mZKlN5V5fa3eq6dmi2l2iacvCfNn2x8ASBpA52XG7wH32Z6c13sUWDFvf3v+\n75+ArYHvA6dKmotUZHZRn95JnfQ0BqrZxklB88XUSvHUo+Ky47f/BcCBeSKL4q+KxX0P4ONy5TmK\ny3Jr8gdS67K67T/1IaYQKlGLX/o7lhk/kpevJWk+YDqpG/dUXr4xcD+wPul8BVK37BekxAmhadXi\nKtksZcbAUqRkuIB0UeBc22/n9ZeTdAtp6qWfAdh+CFiEVNYcQtMq1cLYHg+MLzxfLD88trDaryUN\nA960vUsnu/mV7UeLCyR9Fpho+7FO1g+haTR88KWk/YB9gb0aHUsIPYmKy35qtitA0HwxtVI8UXEZ\nQg1FwoRQQiRMCCU0/KS/rL5WXEblZKiFaGFCKCESJoQSImFCKKEhCROVm6FVRQsTQgk9XiWTNBL4\nCrAAsCxwBvA0cBLwb9LNX79te4qkU4EN837Ptn1xF1WWxf1/HRhFKht40PaomryzEOqgt5eVVwfW\nBBYC/gq8CmyW7wFzKrCTpBeANWxvKGkw8Iika/P2HassrwOQND9wNLC+7Y8kXS5pQ9v31O4tJvWs\n+Gu2akJovphml3h6mzB35kKv1yW9S7q1+NWSIN0I9nVgCeBOANvvS3oMWDlv37HKst3qwHLArXlf\nC5LmAKh5wtRrLFOzjZOC5oupleLpKZF6mzDFc53ppFuIDyuuIOl7pCrKdnPndYvbFysvIU2c8ZDt\nuN14aAm9PelfX9JASYsBQ4DpklYDkHSQpM+TzlOG5WXzk2r4i1WWMHOVJYCBVSUtnrc7XtIy/Xg/\nIdRVbxNmImlKpXHAj4BvAhdKuhvYCLDtCcBDku4CbgN+YPv9vP0sVZakjT4gndPcJOkeYFHgpX6/\nqxDqpLddsmdsH95h2XodV7L9oy6271hlOYlcuWn7auDqXsYRQkPF7zAhlBAVl/3UbFeAoPliaqV4\nouIyhBqKhAmhhEiYEEqIissQSogWJoQSImFCKCESJoQSapYwtaiilDRe0hq1iimEWosWJoQSenWV\nTNJywCXAtLzN7sDJpNqVfwF75lVnuv+l7dGSPke6JcZ00p3J9ioUns1UnVm7txVCffT2svKOwG22\nT5C0FrAH8LLtXSXtAmxLutdlx/tfjgbOBL5v+z5JhwOHSLqDrqsz6yIqLhtrdomntwnzB+CafJex\nK4GlSTdxxfZlkM5hmPX+lwCr2b4vP/4jcBzwDl1XZ9ZFVFw2TivFU5N7XOah+V8A7iZ1xbbuYtue\n7n7cXoXZRtfVmSE0rV4lTO52rWH7WtKkFW3Al/Nr20g6qpvNH5W0fn68CfAg3VdnhtC0etslexI4\nV9Jk0on/9sAoSXeSplrai667VAcD50hqA94Cvmn7XUnt1Zlzkasz80QYITStlquHGT7quj4FXK+x\nZM3WP4fmi6mV4ol6mBBqKBImhBJabnj/DWO2a6rmPXyyRAsTQgmRMCGU0HJdsu4qLqOqMtRbtDAh\nlBAJE0IJkTAhlBAJE0IJDU0YSfNLmtjIGEIoI1qYEEqo2WVlSQuSissGATcB3yaNbP4lMByYB9ic\nVAdzFTAvMKGw/VN5u1dtn1iruEKopVr+DrMn8JjtQyTtT0qMOYEnbP9U0mXAZqRqzUdtf0/SCOAb\nefu5gJtt39LXABpVBtts5bfQfDHNLvHUMmFWJd8kCbgeOCI/vjv/90XSTV9XI5cnF9Zvd39/AmjE\nGLNmG7oOzRdTK8VTkxLlXhrAx2XGxZqVqR3WKa7X8fhTahhPCDVXy4R5Blg7P966m/VcWG/TGh4/\nhLqrZcJcBGwsaTywBOmEvzNjgf/MUy2JmVujEJpaLc9hBgOjbd+aJ73YxPaW7S92uKlssWU5Lr++\nfA1jCaEuapkw7wCHSTqWdJ5ycA33HUJTqFnC2H4b2KpW++tKVFyGRopf+kMoIRImhBIiYUIooeVL\nlKMsOVQpWpgQSoiECaGESJgQSqjkHEbS8sDfgIc6vDSCdJeyz5EGaU4FRtp+voq4QiirypN+2x5W\nXCBpL2Ca7Q0Kz/cHflBhXCH0WqOvki0EzChAsP3rBsYSQo8anTCXACMlmVSefJXtCT1sM5NmqORr\nhhg6araYZpd4qkwY5aH/7Wz7O/muzBsBWwK/lXSB7eN6u9NGjytrtmpCaL6YWimenhKp0ecwcwNT\nbd8N3C3pfFLZcq8TJoQqNfqy8gXA3oXnywLPNiiWEHrUyC4ZwJHAkZJGAh+RbjD73QpjCqGUShLG\n9kQKV8M6+HoVMYRQC43ukoXQUhp9Wbm0qLgMjRQtTAglRMKEUEIkTAgltNw5TLHiMqotQ9WihQmh\nhEiYEEqIhAmhhLqew+RKy2eANW0/kpeNzC9fDpwOrEcaEvMKsL/tF+oZUwj9UUUL8xhwSifLTwde\nsr2m7XXzOrdImquCmELokyoS5iFgsqTiJa0hpHvInNS+wPY9wH3AdhXEFEKfVHVZ+UfAWEkb5OcD\nSfe+nNphvYdJ94zplWap4muWOIqaLabZJZ6qRis/JenPpFliIN1EaWAnqw6g6xsxzaIZxpQ1WzUh\nNF9MrRRPlfe47Mlo0mwwc5HucalccVn0H6RznhCaUmUJY/sV4FrgO8B7wA3Af7e/nrtrawI3VhVT\nCGVVPTTmND6uqDwUOEXSX0nVlq8BO9nudZcshKrVNWFypeXIwvPJpBvGtjusnscPodbil/4QSoiE\nCaGElhveHyXKoZGihQmhhEiYEEpouS5ZVFyGRooWJoQSImFCKCESJoQSImFCKKGqm8IeAOxBGjM2\nCDiKdBOl3YBJhVXvt31EFTGF0Bd1T5hc1/9tYB3b/5a0MnA+8EfgTNtn1zuGEGqlii7ZgsC8wNyQ\nislsb1LBcUOoubq3MLb/Kul+4DlJN5Fu/np1LfbdLGWvzRJHUbPFNLvEM6Ctra3GoXRO0qrAVsDu\npAKyu4Bdmfkc5kzb13S3n+GjrpsRcDP8cNls5bfQfDG1UjxDhw4Z0N22VZzDDADmsf048Liks4An\ngOWIc5jQYqo4h9kHOC8nDqRzmjmAVys4dgg1VcVl5QuBVYD7JE0mTYJxMLAOcIikHQvrvmk77nkZ\nmlYVJ/3TgMM7eelGCpNghNAK4pf+EEpoueH9UXEZGilamBBKiIQJoYRImBBKaLmEGT7qOvY+ZVyj\nwwifUC2XMCE0UiRMCCVEwoRQQlUVlysDPwOGkm6kdC/p1/9bC6stDMxte9UqYgqhL6oYrTwQuAo4\nyPadeRDm/wDH2h5WWO+KvF4ITauKFmYL0v0s7wSw3SbpCNJdyACQtC0wn+3LKognhD6rImFWId3s\ndQbbH7Y/ljQE+AmpuKzXmqmCr5liaddsMc0u8VSRMF3dALbdKcC5tp8vs9NmGU/WbNWE0HwxtVI8\nPSVSFQnzBHBgcYGkeYCVgQWALwIHVRBHCP1WxWXl24BPSxoOIGkOUhdsN+DnwL62p3ezfQhNo4oC\nsumStiKVKR8HTCElkYH9gf+RVNxkJ9uv1TuuEPqikt9hbP8TGN7JS5dWcfwQaiV+6Q+hhKi4DKGE\naGFCKCESJoQSImFCKKHlEiYqLkMjtVzChNBIkTAhlBAJE0IJVRSQdVVtaWAN25PzesOAA23v2MWu\nQmi4urYwhWrLU22vC6ydXzq2nscNoV7q3SWbpdoSOAIYXefjhlAX9e6SdVltmUco3yxpWn5pIeDp\n3u64mSr4mimWds0W0+wST70Tpqdqy607nsP0dsfNMp6s2aoJofliaqV4Gl1x2V21ZQgtp97nMF1V\nW46o83FDqIu6JkwuPd4K2FfSg8AE4B3guHoeN4R6qaJEuatqy+U7rDceGF/veELoj/ilP4QSImFC\nKCFKlEMoIVqYEEqIhAmhhJZLmOGjrmt0COETrOUSJoRGioQJoYRImBBKqKLicnngb8BDwABgKnCS\n7TskTQReAKYVNhltO6aFCU2pqt9h3H4/S0krAjdI2iW/NmOIfwjNrvIume1ngBOBA6o+dgj91ahz\nmAeB1Rp07BD6rFFDY4bw8XlLsUwZUhftw062mWF2KXetp2aLaXaJp1EJszbwF9IQ/9LnMM00lqzZ\nym+h+WJqpXh6SqTKu2T5pP8w4Iyqjx1Cf1XVwkjSeGAe0qQYB9h+vpOZYwAutX1eRXGFUEoVFZcT\nSecsnb22fL2PH0ItxS/9IZQQCRNCCS2XMDeM2a7RIYRPsJZLmBAaKRImhBIiYUIoIRImhBIiYUIo\nIRImhBIiYUIoIRImhBIiYUIoYUBbW1ujYwihZUQLE0IJkTAhlBAJE0IJkTAhlBAJE0IJkTAhlBAJ\nE0IJLXWPS0lnAP8JtAGH2H6gATGcCmxM+uxOBrYFvgi8kVf5qe0bK4plGHAF8Pe86G/AqcDFpNl5\n/gnsYfujKuLJMe0D7FFYtDZpptPBwPt52SjbD9U5jjWA64AzbJ8t6VN08rlI2g04FJgOnGf7f7vb\nb8skjKRNgJVtry9pVeACYP2KY9gUWCPHsChpMsJxwA9t/77KWArutL1jIcYLgXNsXyHpJGBv4BdV\nBZP/4P43x7IJsDOwOvBN249WEYOkwcBZwB2FxaPp8LlIGgscC6wLTAEekHSN7Te72ncrdck2A64F\nsP04sLCkBSqO4S5gp/z4bdK35sCKY+jJMOD6/PgGYPPGhcKxwAkNOO5HwH8BLxWWDWPWz2U94AHb\n7+Tpie8BNuxuxy3TwgBLku4x0+61vOzdqgKwPY2PuxX7ADeR5og+UNJhwKvAgbZfryomYDVJ1wOL\nAMcDgwtdsFeBpSqMZQZJ6wAv2H45T9g4WtJiwOPAoT3Nn90ftqcCU/Nx23X2uSxJ+juiw/IutVIL\n09GARh1Y0nakhDmQ1C/+ge0vAw8D/11hKE+RkmQ7YC9SV6j4Jdiwzwj4FnBRfnwm8H3bXyKdKzT6\nViddfS49fl6t1MK8RPpGaLc06eStUpK2An4EfMX2O8zcT76eas8XJgG/y0+fkfQysI6kQfkbfBlm\n7pZUaRhwEIDtawrLbwBGNCCeyZ18Lh3/ppYB/q+7nbRSC/MHYEcASWsBL9mudEp4SQsCPwW2aT8x\nlHSVpBXyKsOASk5s87F3k3R4frwksARwIbBDXmUH4Jaq4inEtTQw2fYUSQMk3S5pofzyMCr8jApu\nZ9bP5T7SF8xCkuYnnb/c3d1OWmp4v6RTgBnNuu2/Vnz8fUldricLiy8kdc0+ACaTrga9WlE8Q4BL\ngYWAuUnds78AY4F5gX/keP5dRTyFuL4I/Nj21vn5zsCRpPO/ScA+tj+o8/HHkG6n8u98zN1IXcSZ\nPhdJOwLfJ/1UcZbt33S375ZKmBAarZW6ZCE0XCRMCCVEwoRQQiRMCCVEwoRQQiv9cFk5ScsDBv5U\nWDwncJTtu7rZbhjpsupG3ayzNLCK7XGSRgIDexop24tYJ9hetq/76MMxdwUusz29qmM2WiRMz16z\nPaz9iaTVgNslLWO7P9fkNwVWBcbZvqh/ITbM8cDlpN/FPhEiYUqy/ZikQcBiwGt5qPiGwCDgTuCI\n4vqSNgJ+QhpBOx+wP/AWcCIwQNKbwAKk/xfzAG/ZPilvezTphrrHAOcAK+Xnv7U9pqsYc4v1FdLY\nqLWAS0g/bG6al20ODCUN67kZ+ELedBfbkyR9lTTS+IP8b9+8fCJpKM4KwGM5njskbU8a7rInaZj8\nv4ARtt/O25wJbA18BtjP9h2SVgZ+RTot+Bfph8RJkg4ilQTMCTwB7F/PgZplxTlMSZK2JY1wfV3S\nTsAytjexvS7pD2ibDpssBnw3D848k9Sde470q/PFtk8vrPsb8vCfbARpcOchpKFAm5KGpO8i6fM9\nhLo26Q94C9If/222NyAl7hZ5nRWAC21vDIwHRkmaDzgf2CEf72bgx4X9PmV7J9vH5eeb5WFCg4At\nbW8CTAR2L2zzoe0t834OzsvOJRXbfYlU27STpHWB7YEv2V6fVELxrR7eZ6WihenZUEnj8+PlSMMq\ntrHdlgvK1i+8viDpW/SRwvYvA6dJmje//lZXB7L9sKR58ti0eYGpth/NVZ7L5oIs8msrdThORw/m\nisIXSV+ME/LyF3McAG8UKh/vIVUefhZ4xfaLefl4YL/Cfu/t4nhvADdJmk4aklIcGDs+//cfpDIE\nSIk/Pr/vywAkHZHf1x/z0PzBpKEtTSMSpmczzmEk7UD6hnwqv/YRqaz1tOIG+aS/3cXAd/LJ/TbA\n4T0c71JSKzOY1JVqP85o21eWiHtq8UmuEWnXPox9jg7L2vI/OlnebkrHA0laFjgNWN32q5JO67BK\nZ8duY9YezkfA9bYP7HiMZhFdshJsX0VqIdr/h04Avi5pTgBJx+a+edESwN8lDSRVa86Tl08H5urk\nMJcCw/O/SwvH2TkfYw5Jp0tapJNty1pY0pr58UakFutJYHFJy+Xlm9P1kPc20ntYHHg9J8siwJZ8\n/D67ci/pPAtJI/K54D3A1nnkMJL2l1RpGXpPooUp7wBS7feNwNWkSTnulTQN+DPwLKmuot1PSHX/\n/yCVBlws6VDSMPLfSZpCqtoEwPZzktpILVt7t+YcYHVJfyKVRP++u7rzEiYBIyWNIX157mL7wzyR\nxe8kfUQagb1PF9vfQprgYlvgKUn3A88AxwG/yJ9RVw4EzpN0AKnbtbftFySdA4yX9C9SvcpF/X6X\nNRSjlT+hGvG7zewgumQhlBAtTAglRAsTQgmRMCGUEAkTQgmRMCGUEAkTQgn/D+L0jQrfhj/lAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Xd1D0Hvfv8po",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "ophdwfn9v8pp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### DRILL: Improve this gradient boost model\n",
        "\n",
        "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
        "\n",
        "* Creating new features\n",
        "* Applying more overfitting-prevention strategies like subsampling\n",
        "* More iterations\n",
        "* Trying a different loss function\n",
        "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
        "\n",
        "Have fun!"
      ]
    }
  ]
}